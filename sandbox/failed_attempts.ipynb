{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_spectrogram(wav_file):\n",
    "#{\n",
    "    rate, data = wavfile.read(wav_file)\n",
    "    print(\"File contains\", data.shape[0] / rate, \"seconds of data sampled at\", rate, \"Hz\")\n",
    "    print(\"Time steps in audio recording before spectrogram\", data[:,0].shape)\n",
    "    \n",
    "    nfft = 256              # Length of each window segment\n",
    "    fs = 1000               # Sampling frequencies\n",
    "    noverlap = 128          # Overlap between windows\n",
    "    \n",
    "    if data.ndim == 1:\n",
    "        pxx, freqs, bins, im = plt.specgram(data, nfft, fs, noverlap = noverlap)\n",
    "    elif data.ndim == 2:\n",
    "        pxx, freqs, bins, im = plt.specgram(data[:,0], nfft, fs, noverlap = noverlap)\n",
    "    \n",
    "    print(\"Time steps in input after spectrogram\", pxx.shape, \"\\n\")\n",
    "    return pxx\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Both these files error out due to incomplete wav chunk\n",
    "########################################################\n",
    "\n",
    "# graph_spectrogram('../data/Cinema_paradiso_stripped.wav')\n",
    "# graph_spectrogram('../data/A_ghost_of_a_chance_stripped.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_freq = 101  # Number of frequencies input to the model at each time step of the spectrogram\n",
    "Tx = 5511     # The number of time steps input to the model from the spectrogram (per 10s clip => 0.0018s steps)\n",
    "n_tones = 88  # The number of output nodes = to a vector of 88 on/off piano keys\n",
    "Ty = 1375     # The number of time steps in the output of our model (per 10s clip => .0072s steps)\n",
    "\n",
    "# Only the last spectogram actually gets displayed\n",
    "X1 = graph_spectrogram('../data/audio/Cry_me_a_river_simple.wav')\n",
    "X2 = graph_spectrogram('../data/audio/A_fine_romance_simple.wav')\n",
    "\n",
    "# Clip the ends of X1 and X2 to reshape properly\n",
    "X1_train = song2samples(X1[:,0:137775], Tx, n_freq)\n",
    "X2_train = song2samples(X2[:,0:170841], Tx, n_freq)\n",
    "m = X1_train.shape[0] + X2_train.shape[0]\n",
    "\n",
    "X_train = np.zeros((m, Tx, n_freq))\n",
    "X_train[0:X1_train.shape[0],:,:] = X1_train[:,:,:]\n",
    "X_train[X1_train.shape[0]:m,:,:] = X2_train[:,:,:]\n",
    "\n",
    "print(\"Discretized into 10 sec samples:\")\n",
    "print(\"X1 train set size:\", X1_train.shape)\n",
    "print(\"X2 train set size:\", X2_train.shape)\n",
    "print(\"Final training set size:\", X_train.shape, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid1 = MidiFile('../data/Cry_me_a_river_stripped.mid')\n",
    "mid2 = MidiFile('../data/A_fine_romance_stripped.mid')\n",
    "\n",
    "Y1 = np.zeros((n_tones, 25 * Ty))\n",
    "Y2 = np.zeros((n_tones, 31 * Ty))\n",
    "\n",
    "Y1 = format_label_data(mid1, Y1)\n",
    "Y2 = format_label_data(mid2, Y2)\n",
    "\n",
    "Y1_train = song2samples(Y1, Ty, n_tones)\n",
    "Y2_train = song2samples(Y2, Ty, n_tones)\n",
    "assert m == Y1_train.shape[0] + Y2_train.shape[0]\n",
    "\n",
    "Y_train = np.zeros((m, Ty, n_tones))\n",
    "Y_train[0:Y1_train.shape[0],:,:] = Y1_train[:,:,:]\n",
    "Y_train[Y1_train.shape[0]:m,:,:] = Y2_train[:,:,:]\n",
    "\n",
    "print(\"\\nDiscretized into 10 sec samples:\")\n",
    "print(\"Y1 train set size:\", Y1_train.shape)\n",
    "print(\"Y2 train set size:\", Y2_train.shape)\n",
    "print(\"Final training set size:\", Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_conv_network(time_batch, n_freq):\n",
    "#{\n",
    "    X_input = Input(shape=(time_batch, n_freq, 1))\n",
    "\n",
    "    # Layer 1: CONV layer\n",
    "    X = Conv2D(10, kernel_size=(3,10000))(X_input)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D(pool_size=(2, 2))(X)\n",
    "    X = Dropout(0.8)(X)\n",
    "\n",
    "    # Layer 2: CONV layer\n",
    "    X = Conv2D(25, kernel_size=(2,1000))(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D(pool_size=(2, 2))(X)\n",
    "    X = Dropout(0.8)(X)\n",
    "\n",
    "    # Layer 3: Time-distributed dense layer\n",
    "    X = Flatten()(X)\n",
    "    X_output = Dense(time_batch, activation = \"sigmoid\")(X) \n",
    "    \n",
    "    model = keras.models.Model(inputs = X_input, outputs = X_output)\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate model and configure for training\n",
    "model = create_conv_network(time_batch, n_freq)\n",
    "opt = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, decay=0.01)\n",
    "early_stop = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)]\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "history = model.fit(X_train, Y_train, batch_size=5, validation_data=(X_val, Y_val), callbacks=early_stop, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('../data/h5/music_model_19_02_18.h5') \n",
    "\n",
    "# List all data in history\n",
    "print(history.history.keys())\n",
    "\n",
    "# Plot with respect to accuracy\n",
    "plt.figure(1)\n",
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.plot(history.history['val_categorical_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'validate'], loc='upper left')\n",
    "\n",
    "# Plot with respect to loss\n",
    "plt.figure(2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'validate'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_spectral_strided_data(spectral_list, time_batch, n_freq, stride):\n",
    "#{    \n",
    "    # Zero pad a time_batch at the end\n",
    "    zpad = np.zeros((time_batch, n_freq))\n",
    "    spectral_array = np.real(spectral_list)\n",
    "    spectral_array = np.concatenate((spectral_array, zpad))\n",
    "    \n",
    "    strided_steps = np.arange(0, m, stride)\n",
    "    X = np.zeros((len(strided_steps), n_freq, time_batch))\n",
    "    \n",
    "    for i in range(len(strided_steps)):\n",
    "        j = strided_steps[i]\n",
    "        X[i,:,:] = spectral_array[j:j+time_batch, :].transpose()\n",
    "    \n",
    "    return X\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reshape FFT data for DenseNet\n",
    "# X_train = np.reshape(np.asarray(spectral_train), (m,-1,1))\n",
    "# X_val = np.reshape(np.asarray(spectral_val), (m,-1,1))\n",
    "# print(f\"Input data shape, train: {X_train.shape}, validate: {X_val.shape}\")\n",
    "\n",
    "# Y_train = generate_contiguous_labels(midi_train, m, sec_per_step_train)\n",
    "# Y_val = generate_contiguous_labels(midi_val, m, sec_per_step_val)\n",
    "# print(f\"Output data shape, train: {Y_train.shape}, validate: {Y_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dense_network(n_freq):\n",
    "#{\n",
    "    # Layer #0: Input\n",
    "    X_input = Input(shape=(n_freq, 1))\n",
    "    \n",
    "    # Layer #1: Conv1D to reduce huge input dim\n",
    "    X = Conv1D(128, kernel_size=16, strides=4)(X_input)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Dropout(0.8)(X)\n",
    "    \n",
    "    # Layer #2: Dense layer\n",
    "    X = Dense(64, activation='relu')(X)\n",
    "    X = Dropout(0.8)(X)\n",
    "\n",
    "    # Layer #3: Dense layer\n",
    "    X = Dense(1, activation='relu')(X)\n",
    "    X = Dropout(0.8)(X)\n",
    "\n",
    "    # Layer #4: Collapse to 1D, then Binary sigmoid\n",
    "    X = Flatten()(X)\n",
    "    X_output = Dense(1, activation = \"sigmoid\")(X) \n",
    "    \n",
    "    model = keras.models.Model(inputs = X_input, outputs = X_output)\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min/Max students uncheated upon: 0/4\n",
      "Expected number of students uncheated upon: 1.99957\n"
     ]
    }
   ],
   "source": [
    "# Generate model and configure for training\n",
    "model = create_dense_network(n_freq)\n",
    "opt = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, decay=0.01)\n",
    "early_stop = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)]\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "history = model.fit(X_train, Y_train, batch_size=m, validation_data=(X_val, Y_val), callbacks=early_stop, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all data in history\n",
    "print(history.history.keys())\n",
    "\n",
    "# Plot with respect to accuracy\n",
    "plt.figure(1)\n",
    "plt.plot(history.history['binary_accuracy'])\n",
    "plt.plot(history.history['val_binary_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'validate'], loc='upper left')\n",
    "\n",
    "# Plot with respect to loss\n",
    "plt.figure(2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'validate'], loc='upper left')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
